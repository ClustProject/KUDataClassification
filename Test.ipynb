{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddcd388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import main_classificaiton as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1b1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57151175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'seq_len': 128,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21129aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d7b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(2947, 9, 128)\n"
     ]
    }
   ],
   "source": [
    "# scaling time series data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "if len(train_x.shape) < 3:\n",
    "    scaler = scaler.fit(train_x)\n",
    "else:\n",
    "    origin_shape = train_x.shape\n",
    "    scaler = scaler.fit(np.transpose(train_x, (0, 2, 1)).reshape(-1, origin_shape[1]))\n",
    "\n",
    "scaled_x_data = []\n",
    "for x_data in [train_x, test_x]:\n",
    "    if len(train_x.shape) < 3:\n",
    "        x_data = scaler.transform(x_data)\n",
    "    else:\n",
    "        x_data = scaler.transform(np.transpose(x_data, (0, 2, 1)).reshape(-1, origin_shape[1]))\n",
    "        x_data = np.transpose(x_data.reshape(-1, origin_shape[2], origin_shape[1]), (0, 2, 1))\n",
    "\n",
    "    scaled_x_data.append(x_data)\n",
    "train_x, test_x = scaled_x_data        \n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (95, 24, 144)\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (42, 24, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856bde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d6d315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7866 Acc: 0.2522\n",
      "val Loss: 1.7781 Acc: 0.3562\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 1.0309 Acc: 0.5445\n",
      "val Loss: 1.1062 Acc: 0.5269\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.9873 Acc: 0.5570\n",
      "val Loss: 1.0418 Acc: 0.4908\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.9661 Acc: 0.5678\n",
      "val Loss: 1.0172 Acc: 0.5058\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.9543 Acc: 0.5718\n",
      "val Loss: 1.0311 Acc: 0.5105\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.9646 Acc: 0.5705\n",
      "val Loss: 1.0260 Acc: 0.5017\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.9402 Acc: 0.5798\n",
      "val Loss: 0.9992 Acc: 0.5432\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.9203 Acc: 0.5911\n",
      "val Loss: 0.9986 Acc: 0.5221\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.9095 Acc: 0.6101\n",
      "val Loss: 1.0059 Acc: 0.5622\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.8829 Acc: 0.6300\n",
      "val Loss: 0.9972 Acc: 0.5568\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.8737 Acc: 0.6189\n",
      "val Loss: 0.9597 Acc: 0.5636\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.6764 Acc: 0.7315\n",
      "val Loss: 0.7555 Acc: 0.6805\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.4947 Acc: 0.8260\n",
      "val Loss: 0.5623 Acc: 0.7818\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.5553 Acc: 0.8293\n",
      "val Loss: 0.6221 Acc: 0.7689\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.3595 Acc: 0.8713\n",
      "val Loss: 0.4553 Acc: 0.8538\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.5245 Acc: 0.7602\n",
      "val Loss: 0.7252 Acc: 0.7199\n",
      "\n",
      "Training complete in 2m 38s\n",
      "Best val Acc: 0.878994\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d304c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987784187309128\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69be2cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7808 Acc: 0.1845\n",
      "val Loss: 1.7641 Acc: 0.1992\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 1.0581 Acc: 0.5329\n",
      "val Loss: 1.0990 Acc: 0.4854\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.9882 Acc: 0.5638\n",
      "val Loss: 1.1267 Acc: 0.5010\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.6256 Acc: 0.7725\n",
      "val Loss: 0.6747 Acc: 0.6676\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.4949 Acc: 0.7954\n",
      "val Loss: 0.5328 Acc: 0.7825\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.4421 Acc: 0.8051\n",
      "val Loss: 0.4884 Acc: 0.7906\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.4072 Acc: 0.8262\n",
      "val Loss: 0.4703 Acc: 0.7961\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.3840 Acc: 0.8339\n",
      "val Loss: 0.4865 Acc: 0.7743\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.3570 Acc: 0.8538\n",
      "val Loss: 0.4210 Acc: 0.8396\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.3635 Acc: 0.8519\n",
      "val Loss: 0.4114 Acc: 0.8423\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.3189 Acc: 0.8738\n",
      "val Loss: 0.3833 Acc: 0.8729\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.3139 Acc: 0.8779\n",
      "val Loss: 0.3782 Acc: 0.8919\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.2614 Acc: 0.9009\n",
      "val Loss: 0.3622 Acc: 0.8912\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.2478 Acc: 0.9024\n",
      "val Loss: 0.3507 Acc: 0.8872\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.2332 Acc: 0.9104\n",
      "val Loss: 0.3747 Acc: 0.8987\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.2230 Acc: 0.9104\n",
      "val Loss: 0.3212 Acc: 0.8695\n",
      "\n",
      "Training complete in 2m 31s\n",
      "Best val Acc: 0.914344\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4002cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827281981676281\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80aae9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7267 Acc: 0.3486\n",
      "val Loss: 1.6268 Acc: 0.3936\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.8740 Acc: 0.7089\n",
      "val Loss: 0.9253 Acc: 0.7233\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.5772 Acc: 0.8079\n",
      "val Loss: 0.6615 Acc: 0.8097\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.4651 Acc: 0.8257\n",
      "val Loss: 0.5759 Acc: 0.7899\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.4086 Acc: 0.8402\n",
      "val Loss: 0.5197 Acc: 0.8117\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.3792 Acc: 0.8493\n",
      "val Loss: 0.4863 Acc: 0.8300\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.3586 Acc: 0.8572\n",
      "val Loss: 0.4723 Acc: 0.8090\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.3409 Acc: 0.8609\n",
      "val Loss: 0.4487 Acc: 0.8321\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.3283 Acc: 0.8655\n",
      "val Loss: 0.4280 Acc: 0.8423\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.3107 Acc: 0.8737\n",
      "val Loss: 0.4115 Acc: 0.8545\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.3023 Acc: 0.8774\n",
      "val Loss: 0.4176 Acc: 0.8260\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.2908 Acc: 0.8837\n",
      "val Loss: 0.4070 Acc: 0.8341\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.2804 Acc: 0.8895\n",
      "val Loss: 0.3843 Acc: 0.8518\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.2726 Acc: 0.8913\n",
      "val Loss: 0.3792 Acc: 0.8511\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.2637 Acc: 0.8973\n",
      "val Loss: 0.3752 Acc: 0.8559\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.2577 Acc: 0.8964\n",
      "val Loss: 0.3767 Acc: 0.8450\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val Acc: 0.887152\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422d2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8092975907702749\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fd59aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.5169 Acc: 0.6674\n",
      "val Loss: 1.4140 Acc: 0.8899\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.5008 Acc: 0.9475\n",
      "val Loss: 0.5601 Acc: 0.8946\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.2327 Acc: 0.9568\n",
      "val Loss: 0.3736 Acc: 0.8987\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.1450 Acc: 0.9628\n",
      "val Loss: 0.3249 Acc: 0.9007\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.1045 Acc: 0.9672\n",
      "val Loss: 0.3851 Acc: 0.8885\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.0925 Acc: 0.9662\n",
      "val Loss: 0.2981 Acc: 0.9062\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.0761 Acc: 0.9694\n",
      "val Loss: 0.3331 Acc: 0.9211\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.0746 Acc: 0.9680\n",
      "val Loss: 0.3098 Acc: 0.9177\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.0654 Acc: 0.9742\n",
      "val Loss: 0.3247 Acc: 0.9266\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.0639 Acc: 0.9730\n",
      "val Loss: 0.2965 Acc: 0.9286\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.0627 Acc: 0.9713\n",
      "val Loss: 0.3549 Acc: 0.8939\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.0554 Acc: 0.9733\n",
      "val Loss: 0.3783 Acc: 0.9218\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.0531 Acc: 0.9752\n",
      "val Loss: 0.4274 Acc: 0.9245\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.0517 Acc: 0.9770\n",
      "val Loss: 0.4255 Acc: 0.9007\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0533 Acc: 0.9743\n",
      "val Loss: 0.4601 Acc: 0.9123\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0496 Acc: 0.9779\n",
      "val Loss: 0.3314 Acc: 0.9490\n",
      "\n",
      "Training complete in 1m 59s\n",
      "Best val Acc: 0.950374\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a94ecb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9195792331184256\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f02d9",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfe6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64)\n",
      "(7352,)\n",
      "(2947, 64)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99ed1f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7738 Acc: 0.2080\n",
      "val Loss: 1.7019 Acc: 0.2570\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.7111 Acc: 0.7990\n",
      "val Loss: 0.7149 Acc: 0.8097\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.4213 Acc: 0.8907\n",
      "val Loss: 0.4824 Acc: 0.8708\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.2872 Acc: 0.9243\n",
      "val Loss: 0.3738 Acc: 0.8926\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.2214 Acc: 0.9349\n",
      "val Loss: 0.3160 Acc: 0.9021\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.1850 Acc: 0.9418\n",
      "val Loss: 0.2853 Acc: 0.9089\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.1560 Acc: 0.9493\n",
      "val Loss: 0.2693 Acc: 0.9116\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.1415 Acc: 0.9483\n",
      "val Loss: 0.2598 Acc: 0.9184\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.1320 Acc: 0.9515\n",
      "val Loss: 0.2543 Acc: 0.9239\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.1207 Acc: 0.9536\n",
      "val Loss: 0.2525 Acc: 0.9266\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.1144 Acc: 0.9565\n",
      "val Loss: 0.2493 Acc: 0.9266\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.1110 Acc: 0.9582\n",
      "val Loss: 0.2451 Acc: 0.9279\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.1040 Acc: 0.9597\n",
      "val Loss: 0.2459 Acc: 0.9286\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.0995 Acc: 0.9600\n",
      "val Loss: 0.2436 Acc: 0.9279\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0996 Acc: 0.9606\n",
      "val Loss: 0.2426 Acc: 0.9293\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0975 Acc: 0.9611\n",
      "val Loss: 0.2404 Acc: 0.9293\n",
      "\n",
      "Training complete in 0m 15s\n",
      "Best val Acc: 0.929980\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config = config5\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb3bdf54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9172039362063116\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
