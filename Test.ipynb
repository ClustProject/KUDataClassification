{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_classificaiton as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 2. GRU model (w/o data representation)\n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 2,  # recurrent layers의 수, int(default: 2, 범위: 1 이상)\n",
    "            'hidden_size': 64,  # hidden state의 차원, int(default: 64, 범위: 1 이상)\n",
    "            'dropout': 0.1,  # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bidirectional': True,  # 모델의 양방향성 여부, bool(default: True)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 3. CNN_1D model (w/o data representation)\n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'seq_len': 128,  # 데이터의 시간 길이, int\n",
    "            'output_channels': 64, # convolution layer의 output channel, int(default: 64, 범위: 1 이상, 2의 지수로 설정 권장)\n",
    "            'kernel_size': 3, # convolutional layer의 filter 크기, int(default: 3, 범위: 3 이상, 홀수로 설정 권장)\n",
    "            'stride': 1, # convolution layer의 stride 크기, int(default: 1, 범위: 1 이상)\n",
    "            'padding': 0, # padding 크기, int(default: 0, 범위: 0 이상)\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150,  # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 4. LSTM_FCNs model (w/o data representation)\n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        'training': True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        'best_model_path': './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,  # 데이터의 변수 개수, int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'num_layers': 1,  # recurrent layers의 수, int(default: 1, 범위: 1 이상)\n",
    "            'lstm_drop_out': 0.4, # LSTM dropout 확률, float(default: 0.4, 범위: 0 이상 1 이하)\n",
    "            'fc_drop_out': 0.1, # FC dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}\n",
    "\n",
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config5 = {\n",
    "        'model': 'FC', # classification에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/fc.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,  # 데이터의 변수 개수(representation 차원), int\n",
    "            'num_classes': 6,  # 분류할 class 개수, int\n",
    "            'drop_out': 0.1, # dropout 확률, float(default: 0.1, 범위: 0 이상 1 이하)\n",
    "            'bias': True, # bias 사용 여부, bool(default: True)\n",
    "            'num_epochs': 150, # 학습 epoch 횟수, int(default: 150, 범위: 1 이상)\n",
    "            'batch_size': 64,  # batch 크기, int(default: 64, 범위: 1 이상, 컴퓨터 사양에 적합하게 설정)\n",
    "            'lr': 0.0001,  # learning rate, float(default: 0.0001, 범위: 0.1 이하)\n",
    "            'device': 'cuda'  # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7789 Acc: 0.2663\n",
      "val Loss: 1.7555 Acc: 0.3569\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.9261 Acc: 0.6154\n",
      "val Loss: 1.0606 Acc: 0.5561\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.6527 Acc: 0.7092\n",
      "val Loss: 0.6196 Acc: 0.7260\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.5330 Acc: 0.7543\n",
      "val Loss: 0.6024 Acc: 0.7138\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.4484 Acc: 0.8147\n",
      "val Loss: 0.5414 Acc: 0.7675\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.4056 Acc: 0.8371\n",
      "val Loss: 0.5199 Acc: 0.8124\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.3437 Acc: 0.8662\n",
      "val Loss: 0.5137 Acc: 0.8341\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.2697 Acc: 0.8927\n",
      "val Loss: 0.4364 Acc: 0.8668\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.2342 Acc: 0.9094\n",
      "val Loss: 0.4039 Acc: 0.8736\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.1545 Acc: 0.9391\n",
      "val Loss: 0.3710 Acc: 0.8946\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.1312 Acc: 0.9495\n",
      "val Loss: 0.2584 Acc: 0.9313\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.1397 Acc: 0.9469\n",
      "val Loss: 0.3855 Acc: 0.9069\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.1120 Acc: 0.9577\n",
      "val Loss: 0.3268 Acc: 0.9191\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.1114 Acc: 0.9561\n",
      "val Loss: 0.3750 Acc: 0.9130\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0920 Acc: 0.9609\n",
      "val Loss: 0.5505 Acc: 0.9062\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0997 Acc: 0.9595\n",
      "val Loss: 0.2485 Acc: 0.9313\n",
      "\n",
      "Training complete in 2m 7s\n",
      "Best val Acc: 0.931339\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "config = config1\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8591788259246692\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7381 Acc: 0.2835\n",
      "val Loss: 1.6610 Acc: 0.3725\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.8096 Acc: 0.6638\n",
      "val Loss: 0.8608 Acc: 0.6818\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.4127 Acc: 0.8085\n",
      "val Loss: 0.5333 Acc: 0.8056\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.3282 Acc: 0.8713\n",
      "val Loss: 0.4935 Acc: 0.8654\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.1819 Acc: 0.9415\n",
      "val Loss: 0.2424 Acc: 0.9354\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.1502 Acc: 0.9420\n",
      "val Loss: 0.2254 Acc: 0.9354\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.1279 Acc: 0.9492\n",
      "val Loss: 0.2140 Acc: 0.9402\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.1152 Acc: 0.9517\n",
      "val Loss: 0.2132 Acc: 0.9381\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.1092 Acc: 0.9537\n",
      "val Loss: 0.2147 Acc: 0.9388\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.1040 Acc: 0.9566\n",
      "val Loss: 0.2135 Acc: 0.9368\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.1051 Acc: 0.9565\n",
      "val Loss: 0.2109 Acc: 0.9388\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.0990 Acc: 0.9570\n",
      "val Loss: 0.2156 Acc: 0.9266\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.0927 Acc: 0.9621\n",
      "val Loss: 0.2335 Acc: 0.9259\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.0897 Acc: 0.9624\n",
      "val Loss: 0.2514 Acc: 0.9225\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0899 Acc: 0.9638\n",
      "val Loss: 0.2499 Acc: 0.9239\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0880 Acc: 0.9651\n",
      "val Loss: 0.2733 Acc: 0.9137\n",
      "\n",
      "Training complete in 2m 8s\n",
      "Best val Acc: 0.942216\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "config = config2\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8853070919579233\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6921 Acc: 0.4606\n",
      "val Loss: 1.5258 Acc: 0.6220\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.3617 Acc: 0.8696\n",
      "val Loss: 0.6173 Acc: 0.8205\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.2393 Acc: 0.9169\n",
      "val Loss: 0.5575 Acc: 0.8695\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.1748 Acc: 0.9379\n",
      "val Loss: 0.4917 Acc: 0.9001\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.1335 Acc: 0.9515\n",
      "val Loss: 0.4622 Acc: 0.9075\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.1101 Acc: 0.9575\n",
      "val Loss: 0.4530 Acc: 0.9103\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.0967 Acc: 0.9587\n",
      "val Loss: 0.4298 Acc: 0.9075\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.0870 Acc: 0.9617\n",
      "val Loss: 0.4059 Acc: 0.9123\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.0807 Acc: 0.9638\n",
      "val Loss: 0.3856 Acc: 0.9130\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.0757 Acc: 0.9645\n",
      "val Loss: 0.3565 Acc: 0.9164\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.0728 Acc: 0.9641\n",
      "val Loss: 0.3594 Acc: 0.9252\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.0675 Acc: 0.9684\n",
      "val Loss: 0.3703 Acc: 0.9252\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.0638 Acc: 0.9687\n",
      "val Loss: 0.3622 Acc: 0.9252\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.0618 Acc: 0.9718\n",
      "val Loss: 0.3619 Acc: 0.9259\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0595 Acc: 0.9736\n",
      "val Loss: 0.3708 Acc: 0.9259\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0586 Acc: 0.9721\n",
      "val Loss: 0.3977 Acc: 0.9259\n",
      "\n",
      "Training complete in 0m 29s\n",
      "Best val Acc: 0.926581\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "config = config3\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066847641669495\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.5299 Acc: 0.5790\n",
      "val Loss: 1.4081 Acc: 0.6234\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.5186 Acc: 0.9386\n",
      "val Loss: 0.6188 Acc: 0.9150\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.2323 Acc: 0.9604\n",
      "val Loss: 0.4559 Acc: 0.9055\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.1432 Acc: 0.9640\n",
      "val Loss: 0.4200 Acc: 0.9184\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.1077 Acc: 0.9653\n",
      "val Loss: 0.4246 Acc: 0.9137\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.0802 Acc: 0.9725\n",
      "val Loss: 0.4375 Acc: 0.9239\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.0826 Acc: 0.9663\n",
      "val Loss: 0.4266 Acc: 0.9137\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.0617 Acc: 0.9745\n",
      "val Loss: 0.4401 Acc: 0.9021\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.0583 Acc: 0.9750\n",
      "val Loss: 0.4615 Acc: 0.9191\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.0635 Acc: 0.9723\n",
      "val Loss: 0.4184 Acc: 0.9109\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.0496 Acc: 0.9779\n",
      "val Loss: 0.4195 Acc: 0.9218\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.0555 Acc: 0.9764\n",
      "val Loss: 0.3962 Acc: 0.9211\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.0485 Acc: 0.9794\n",
      "val Loss: 0.3860 Acc: 0.9198\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.0470 Acc: 0.9801\n",
      "val Loss: 0.3538 Acc: 0.9259\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.0502 Acc: 0.9759\n",
      "val Loss: 0.3390 Acc: 0.9252\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0455 Acc: 0.9791\n",
      "val Loss: 0.4271 Acc: 0.9198\n",
      "\n",
      "Training complete in 1m 36s\n",
      "Best val Acc: 0.933379\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "config = config4\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216152019002376\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64)\n",
      "(7352,)\n",
      "(2947, 64)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model\n",
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7088 Acc: 0.3428\n",
      "val Loss: 1.6546 Acc: 0.4099\n",
      "\n",
      "Epoch 10/150\n",
      "train Loss: 0.7219 Acc: 0.7761\n",
      "val Loss: 0.7332 Acc: 0.7702\n",
      "\n",
      "Epoch 20/150\n",
      "train Loss: 0.4102 Acc: 0.8922\n",
      "val Loss: 0.4728 Acc: 0.8872\n",
      "\n",
      "Epoch 30/150\n",
      "train Loss: 0.2763 Acc: 0.9265\n",
      "val Loss: 0.3520 Acc: 0.9001\n",
      "\n",
      "Epoch 40/150\n",
      "train Loss: 0.2140 Acc: 0.9371\n",
      "val Loss: 0.2944 Acc: 0.9069\n",
      "\n",
      "Epoch 50/150\n",
      "train Loss: 0.1795 Acc: 0.9437\n",
      "val Loss: 0.2656 Acc: 0.9075\n",
      "\n",
      "Epoch 60/150\n",
      "train Loss: 0.1578 Acc: 0.9459\n",
      "val Loss: 0.2516 Acc: 0.9089\n",
      "\n",
      "Epoch 70/150\n",
      "train Loss: 0.1423 Acc: 0.9510\n",
      "val Loss: 0.2446 Acc: 0.9130\n",
      "\n",
      "Epoch 80/150\n",
      "train Loss: 0.1332 Acc: 0.9507\n",
      "val Loss: 0.2379 Acc: 0.9205\n",
      "\n",
      "Epoch 90/150\n",
      "train Loss: 0.1259 Acc: 0.9517\n",
      "val Loss: 0.2365 Acc: 0.9232\n",
      "\n",
      "Epoch 100/150\n",
      "train Loss: 0.1187 Acc: 0.9531\n",
      "val Loss: 0.2364 Acc: 0.9252\n",
      "\n",
      "Epoch 110/150\n",
      "train Loss: 0.1139 Acc: 0.9553\n",
      "val Loss: 0.2359 Acc: 0.9286\n",
      "\n",
      "Epoch 120/150\n",
      "train Loss: 0.1082 Acc: 0.9590\n",
      "val Loss: 0.2345 Acc: 0.9334\n",
      "\n",
      "Epoch 130/150\n",
      "train Loss: 0.1028 Acc: 0.9594\n",
      "val Loss: 0.2364 Acc: 0.9334\n",
      "\n",
      "Epoch 140/150\n",
      "train Loss: 0.1005 Acc: 0.9583\n",
      "val Loss: 0.2383 Acc: 0.9341\n",
      "\n",
      "Epoch 150/150\n",
      "train Loss: 0.0988 Acc: 0.9578\n",
      "val Loss: 0.2383 Acc: 0.9341\n",
      "\n",
      "Training complete in 0m 17s\n",
      "Best val Acc: 0.934738\n",
      "\n",
      "Start testing data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "config = config5\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144893111638955\n",
      "(2947,) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "print(pred.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
