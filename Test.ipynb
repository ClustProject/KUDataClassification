{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import main_classificaiton as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60403381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & LSTM model \n",
    "config1 = {\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/lstm.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,\n",
    "            'num_classes': 6,\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 10, # 학습 시 사용할 epoch 수\n",
    "            'lr': 0.0001\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation & GRU model \n",
    "config2 = {\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,\n",
    "            'num_classes': 6,\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 10, # 학습 시 사용할 epoch 수\n",
    "            'lr': 0.0001\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & CNN_1D model \n",
    "config3 = {\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/cnn_1d.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,\n",
    "            'num_classes': 6,\n",
    "            'seq_len': 128,\n",
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 10, # 학습 시 사용할 epoch 수\n",
    "            'lr': 0.0001\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & LSTM_FCNs model \n",
    "config4 = {\n",
    "        'model': 'LSTM_FCNs', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/lstm_fcn.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 9,\n",
    "            'num_classes': 6,\n",
    "            'num_layers' : 1, # recurrnet layers의 수, Default : 1\n",
    "            'lstm_drop_out' : 0.4, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'fc_drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 256, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 10, # 학습 시 사용할 epoch 수\n",
    "            'lr': 0.0001\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "config5 = {\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "        \"training\": True,  # 학습 여부, 저장된 학습 완료 모델 존재시 False로 설정\n",
    "        \"best_model_path\": './ckpt/gru.pt',  # 학습 완료 모델 저장 경로\n",
    "        'parameter': {\n",
    "            'input_size': 64,\n",
    "            'num_classes': 6,\n",
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 10, # 학습 시 사용할 epoch 수\n",
    "            'lr': 0.0001\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw time series data\n",
    "train_x = pickle.load(open('./data/x_train.pkl', 'rb'))\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "test_x = pickle.load(open('./data/x_test.pkl', 'rb'))\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e20eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & LSTM\n",
    "config = config1\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c178669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2. w/o data representation & GRU\n",
    "config = config2\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3. w/o data representation & CNN_1D\n",
    "config = config3\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b79de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 4. w/o data representation & LSTM_FCNs\n",
    "config = config4\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0487b",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation data\n",
    "train_x = pd.read_csv('./data/ts2vec_repr_train.csv')\n",
    "train_y = pickle.load(open('./data/y_train.pkl', 'rb'))\n",
    "\n",
    "test_x = pd.read_csv('./data/ts2vec_repr_test.csv')\n",
    "test_y = pickle.load(open('./data/y_test.pkl', 'rb'))\n",
    "\n",
    "train_data = {'x': train_x, 'y': train_y}\n",
    "test_data = {'x': test_x, 'y': test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 64)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 64)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_cls = mc.Classification(config, train_data, test_data)\n",
    "model = data_cls.build_model()  # 모델 구축\n",
    "\n",
    "if config[\"training\"]:\n",
    "    best_model = data_cls.train_model(model)  # 모델 학습\n",
    "    data_cls.save_model(best_model, best_model_path=config[\"best_model_path\"])  # 모델 저장\n",
    "\n",
    "pred, prob, acc = data_cls.pred_data(model, best_model_path=config[\"best_model_path\"])  # class 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da4c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "iitp_time_serise",
   "language": "python",
   "name": "iitp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
