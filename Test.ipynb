{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9962b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import main_classificaiton as mc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6b8af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c4dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. w/o data representation & LSTM model \n",
    "config1 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 2. w/o data representation & GRU model \n",
    "config2 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'GRU', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 2, # recurrnet layers의 수, Default : 1\n",
    "            'hidden_size' : 64, # hidden state의 벡터차원 수\n",
    "            'attention' : False, # True일 경우 attention layer를 추가\n",
    "            'dropout' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'bidirectional' : True, # 모델의 양방향성 여부\n",
    "            'batch_size' : 64, #batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 3. w/o data representation & CNN_1D model \n",
    "config3 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'CNN_1D', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'output_channels' : 64, # convolution channel size of output\n",
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'kernel_size' : 3, # convolutional filter size\n",
    "            'stride' : 1, # stride of the convolution. Default = 1 \n",
    "            'padding' : 0, # padding added to both sides of the input. Default = 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 4. w/o data representation & LSTM_FCNs model \n",
    "config4 = {\n",
    "        'with_representation': False, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'LSTM_FCNs', # classification에에 활용할 알고리즘 정의, {'LSTM', 'GRU', 'CNN_1D', 'LSTM_FCNs', 'FC_layer'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'num_layers' : 1, # recurrnet layers의 수, Default : 1\n",
    "            'lstm_drop_out' : 0.4, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'fc_drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 256, # batch size\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}\n",
    "\n",
    "# Case 5. w data representation & fully-connected layers \n",
    "config5 = {\n",
    "        'with_representation': True, # classification에 사용되는 representation이 있을 경우 True, 아닐 경우 False\n",
    "        'model': 'FC', # classification에에 활용할 알고리즘 정의, {'RNN', 'LSTM', 'GRU', 'CNN_1D', 'FC'} 중 택 1\n",
    "\n",
    "        'parameter': {\n",
    "            'window_size' : 128, # input time series data를 windowing 하여 자르는 길이(size)\n",
    "            'drop_out' : 0.1, # If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "            'batch_size' : 64, # batch size\n",
    "            'bias': True, # bias [True, False]\n",
    "            'device': 'cuda', # 학습 환경, [\"cuda\", \"cpu\"] 중 선택\n",
    "            'num_epochs' : 150 # 학습 시 사용할 epoch 수\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e84de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 9, 128)\n",
      "(7352,)\n",
      "(2947, 9, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# Raw data \n",
    "data_dir = './data'\n",
    "\n",
    "train_x = pickle.load(open(os.path.join(data_dir, 'X_train.pkl'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "test_x =  pickle.load(open(os.path.join(data_dir, 'X_test.pkl'), 'rb'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x input_dims x window_size) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564b0770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7789 Acc: 0.2663\n",
      "val Loss: 1.7555 Acc: 0.3569\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0515 Acc: 0.5273\n",
      "val Loss: 1.1120 Acc: 0.5574\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9011 Acc: 0.6179\n",
      "val Loss: 0.9829 Acc: 0.6071\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.7906 Acc: 0.6473\n",
      "val Loss: 0.7324 Acc: 0.6717\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.6235 Acc: 0.7009\n",
      "val Loss: 0.6675 Acc: 0.6540\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5685 Acc: 0.7247\n",
      "val Loss: 0.6062 Acc: 0.7077\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5548 Acc: 0.7473\n",
      "val Loss: 0.6014 Acc: 0.7077\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.5036 Acc: 0.7701\n",
      "val Loss: 0.5988 Acc: 0.7315\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.4671 Acc: 0.7961\n",
      "val Loss: 0.5340 Acc: 0.7668\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.4766 Acc: 0.7903\n",
      "val Loss: 0.5355 Acc: 0.7648\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.4500 Acc: 0.7966\n",
      "val Loss: 0.5546 Acc: 0.7709\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.4335 Acc: 0.8104\n",
      "val Loss: 0.5610 Acc: 0.7757\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.4243 Acc: 0.8150\n",
      "val Loss: 0.6111 Acc: 0.7736\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.4101 Acc: 0.8220\n",
      "val Loss: 0.4941 Acc: 0.8083\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.3858 Acc: 0.8339\n",
      "val Loss: 0.4822 Acc: 0.8185\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.3810 Acc: 0.8380\n",
      "val Loss: 0.4761 Acc: 0.8103\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.3500 Acc: 0.8488\n",
      "val Loss: 0.4839 Acc: 0.8137\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.3218 Acc: 0.8601\n",
      "val Loss: 0.4485 Acc: 0.8253\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.3052 Acc: 0.8704\n",
      "val Loss: 0.4361 Acc: 0.8362\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.2712 Acc: 0.8890\n",
      "val Loss: 0.3961 Acc: 0.8593\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.2477 Acc: 0.9058\n",
      "val Loss: 0.3794 Acc: 0.8790\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.2107 Acc: 0.9279\n",
      "val Loss: 0.3390 Acc: 0.9075\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1688 Acc: 0.9383\n",
      "val Loss: 0.3230 Acc: 0.9177\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1453 Acc: 0.9480\n",
      "val Loss: 0.2621 Acc: 0.9198\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1281 Acc: 0.9520\n",
      "val Loss: 0.2608 Acc: 0.9320\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1074 Acc: 0.9560\n",
      "val Loss: 0.2462 Acc: 0.9218\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1059 Acc: 0.9543\n",
      "val Loss: 0.2440 Acc: 0.9130\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0953 Acc: 0.9577\n",
      "val Loss: 0.2492 Acc: 0.9184\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0955 Acc: 0.9578\n",
      "val Loss: 0.2684 Acc: 0.9171\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0956 Acc: 0.9580\n",
      "val Loss: 0.2446 Acc: 0.9205\n",
      "Training complete in 4m 35s\n",
      "Best val Acc: 0.932019\n",
      "[4 4 4 4 4]\n",
      "[[3.1428826e-03 3.8197242e-05 1.9060582e-05 3.0262794e-03 9.9377233e-01\n",
      "  1.2182280e-06]\n",
      " [4.1432492e-03 4.3443866e-05 2.0092155e-05 2.5938053e-03 9.9319845e-01\n",
      "  9.1327803e-07]\n",
      " [3.7461284e-03 4.0831965e-05 1.9313755e-05 2.6819711e-03 9.9351078e-01\n",
      "  9.5121305e-07]\n",
      " [4.6638870e-03 4.5634115e-05 2.0469381e-05 2.4181218e-03 9.9285114e-01\n",
      "  7.9520919e-07]\n",
      " [4.0701623e-03 4.2379208e-05 1.9275158e-05 2.5371381e-03 9.9333018e-01\n",
      "  8.7419880e-07]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.900844    0.759398    0.807018    0.785311    0.878378   \n",
      "recall       0.860887    0.857749    0.876190    0.849287    0.733083   \n",
      "f1-score     0.880412    0.805583    0.840183    0.816047    0.799180   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000   0.85375     0.855158      0.859629  \n",
      "recall       0.949721   0.85375     0.854486      0.853750  \n",
      "f1-score     0.974212   0.85375     0.852603      0.854423  \n",
      "support    537.000000   0.85375  2947.000000   2947.000000  \n"
     ]
    }
   ],
   "source": [
    "# Case 1. w/o data representation & LSTM\n",
    "config = config1\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefa80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.7381 Acc: 0.2835\n",
      "val Loss: 1.6610 Acc: 0.3725\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.0349 Acc: 0.5535\n",
      "val Loss: 1.1303 Acc: 0.5670\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.7380 Acc: 0.7028\n",
      "val Loss: 0.7783 Acc: 0.6988\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.4793 Acc: 0.7851\n",
      "val Loss: 0.5477 Acc: 0.7879\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.4056 Acc: 0.8165\n",
      "val Loss: 0.5346 Acc: 0.7865\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.3649 Acc: 0.8427\n",
      "val Loss: 0.5201 Acc: 0.8239\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.3154 Acc: 0.8842\n",
      "val Loss: 0.4668 Acc: 0.8804\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.2150 Acc: 0.9359\n",
      "val Loss: 0.2604 Acc: 0.9354\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1714 Acc: 0.9444\n",
      "val Loss: 0.2349 Acc: 0.9381\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1570 Acc: 0.9434\n",
      "val Loss: 0.2270 Acc: 0.9395\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1436 Acc: 0.9447\n",
      "val Loss: 0.2231 Acc: 0.9381\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1376 Acc: 0.9463\n",
      "val Loss: 0.2210 Acc: 0.9388\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1270 Acc: 0.9497\n",
      "val Loss: 0.2103 Acc: 0.9415\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1179 Acc: 0.9519\n",
      "val Loss: 0.2121 Acc: 0.9381\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1155 Acc: 0.9519\n",
      "val Loss: 0.2328 Acc: 0.9307\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1156 Acc: 0.9510\n",
      "val Loss: 0.2119 Acc: 0.9409\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1122 Acc: 0.9481\n",
      "val Loss: 0.2383 Acc: 0.9273\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1033 Acc: 0.9554\n",
      "val Loss: 0.2104 Acc: 0.9402\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1064 Acc: 0.9544\n",
      "val Loss: 0.2250 Acc: 0.9334\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1008 Acc: 0.9572\n",
      "val Loss: 0.2205 Acc: 0.9368\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0957 Acc: 0.9617\n",
      "val Loss: 0.2076 Acc: 0.9415\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1027 Acc: 0.9570\n",
      "val Loss: 0.2142 Acc: 0.9381\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0930 Acc: 0.9626\n",
      "val Loss: 0.2060 Acc: 0.9354\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0988 Acc: 0.9582\n",
      "val Loss: 0.2097 Acc: 0.9327\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0946 Acc: 0.9599\n",
      "val Loss: 0.2051 Acc: 0.9320\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0914 Acc: 0.9619\n",
      "val Loss: 0.2087 Acc: 0.9388\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0948 Acc: 0.9594\n",
      "val Loss: 0.2203 Acc: 0.9347\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0899 Acc: 0.9626\n",
      "val Loss: 0.2163 Acc: 0.9361\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0883 Acc: 0.9641\n",
      "val Loss: 0.2337 Acc: 0.9307\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0989 Acc: 0.9568\n",
      "val Loss: 0.2288 Acc: 0.9313\n",
      "Training complete in 4m 4s\n",
      "Best val Acc: 0.942216\n",
      "[4 4 4 4 4]\n",
      "[[6.6147130e-03 4.3342070e-04 4.0883242e-06 3.1474165e-03 9.8979467e-01\n",
      "  5.6110716e-06]\n",
      " [4.1247495e-03 2.2937769e-04 2.0818159e-06 3.8583579e-03 9.9177963e-01\n",
      "  5.7735538e-06]\n",
      " [4.1023437e-03 2.3258195e-04 2.0553646e-06 3.8146349e-03 9.9184263e-01\n",
      "  5.8144237e-06]\n",
      " [4.1173976e-03 2.3404945e-04 2.0422199e-06 3.7382224e-03 9.9190253e-01\n",
      "  5.8004416e-06]\n",
      " [4.1938112e-03 2.4798021e-04 2.0607722e-06 3.5429583e-03 9.9200737e-01\n",
      "  5.8068881e-06]]\n",
      "                  0.0         1.0         2.0         3.0         4.0    5.0  \\\n",
      "precision    0.871940    0.940774    0.903073    0.824945    0.800000    1.0   \n",
      "recall       0.933468    0.876858    0.909524    0.767821    0.842105    1.0   \n",
      "f1-score     0.901655    0.907692    0.906287    0.795359    0.820513    1.0   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000  537.0   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision   0.88904     0.890122      0.889897  \n",
      "recall      0.88904     0.888296      0.889040  \n",
      "f1-score    0.88904     0.888584      0.888842  \n",
      "support     0.88904  2947.000000   2947.000000  \n"
     ]
    }
   ],
   "source": [
    "# Case 2. w/o data representation & GRU\n",
    "config = config2\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7674f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6921 Acc: 0.4606\n",
      "val Loss: 1.5258 Acc: 0.6220\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.5038 Acc: 0.8153\n",
      "val Loss: 0.6735 Acc: 0.8035\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.3418 Acc: 0.8772\n",
      "val Loss: 0.6024 Acc: 0.8389\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.2777 Acc: 0.8997\n",
      "val Loss: 0.5746 Acc: 0.8559\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.2316 Acc: 0.9199\n",
      "val Loss: 0.5430 Acc: 0.8749\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.1975 Acc: 0.9306\n",
      "val Loss: 0.5114 Acc: 0.8939\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.1694 Acc: 0.9381\n",
      "val Loss: 0.4864 Acc: 0.9028\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.1462 Acc: 0.9486\n",
      "val Loss: 0.4714 Acc: 0.9028\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.1299 Acc: 0.9534\n",
      "val Loss: 0.4587 Acc: 0.9082\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.1189 Acc: 0.9560\n",
      "val Loss: 0.4640 Acc: 0.9055\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.1088 Acc: 0.9575\n",
      "val Loss: 0.4569 Acc: 0.9096\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.1012 Acc: 0.9585\n",
      "val Loss: 0.4401 Acc: 0.9116\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.0946 Acc: 0.9597\n",
      "val Loss: 0.4293 Acc: 0.9109\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.0899 Acc: 0.9611\n",
      "val Loss: 0.4102 Acc: 0.9109\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.0862 Acc: 0.9624\n",
      "val Loss: 0.4008 Acc: 0.9109\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.0839 Acc: 0.9640\n",
      "val Loss: 0.3955 Acc: 0.9082\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.0802 Acc: 0.9631\n",
      "val Loss: 0.3775 Acc: 0.9123\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.0795 Acc: 0.9648\n",
      "val Loss: 0.3650 Acc: 0.9130\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.0753 Acc: 0.9657\n",
      "val Loss: 0.3571 Acc: 0.9164\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.0736 Acc: 0.9657\n",
      "val Loss: 0.3620 Acc: 0.9171\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.0698 Acc: 0.9675\n",
      "val Loss: 0.3570 Acc: 0.9239\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.0691 Acc: 0.9662\n",
      "val Loss: 0.3395 Acc: 0.9252\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0683 Acc: 0.9670\n",
      "val Loss: 0.3499 Acc: 0.9239\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0669 Acc: 0.9699\n",
      "val Loss: 0.3529 Acc: 0.9259\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0666 Acc: 0.9692\n",
      "val Loss: 0.3517 Acc: 0.9245\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0630 Acc: 0.9682\n",
      "val Loss: 0.3559 Acc: 0.9252\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0612 Acc: 0.9709\n",
      "val Loss: 0.3608 Acc: 0.9266\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0595 Acc: 0.9725\n",
      "val Loss: 0.3711 Acc: 0.9232\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0586 Acc: 0.9716\n",
      "val Loss: 0.3824 Acc: 0.9252\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0569 Acc: 0.9730\n",
      "val Loss: 0.3881 Acc: 0.9266\n",
      "Training complete in 0m 44s\n",
      "Best val Acc: 0.926581\n",
      "[4 4 4 4 4]\n",
      "[[1.3835733e-04 2.0991228e-04 1.1575056e-10 1.6110012e-04 9.9949062e-01\n",
      "  4.3692094e-12]\n",
      " [1.7275727e-04 1.2295740e-04 5.7558597e-11 1.2112593e-04 9.9958318e-01\n",
      "  1.3214138e-12]\n",
      " [5.2806929e-05 1.9448133e-04 2.5666153e-11 4.5264318e-05 9.9970740e-01\n",
      "  9.2810276e-13]\n",
      " [2.3459537e-05 2.5745551e-04 8.7912611e-12 3.0766307e-05 9.9968827e-01\n",
      "  8.3606901e-13]\n",
      " [9.8980026e-06 1.1235011e-04 1.7613328e-12 2.4049179e-05 9.9985373e-01\n",
      "  2.5974405e-13]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.965517    0.833969    0.879386    0.850103    0.895257   \n",
      "recall       0.903226    0.927813    0.954762    0.843177    0.851504   \n",
      "f1-score     0.933333    0.878392    0.915525    0.846626    0.872832   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000  0.903631     0.904039      0.906588  \n",
      "recall       0.949721  0.903631     0.905034      0.903631  \n",
      "f1-score     0.974212  0.903631     0.903487      0.904095  \n",
      "support    537.000000  0.903631  2947.000000   2947.000000  \n"
     ]
    }
   ],
   "source": [
    "# Case 3. w/o data representation & CNN_1D\n",
    "config = config3\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59275e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6852 Acc: 0.4542\n",
      "val Loss: 1.7355 Acc: 0.5656\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 1.3337 Acc: 0.6819\n",
      "val Loss: 1.3285 Acc: 0.6567\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.9891 Acc: 0.8062\n",
      "val Loss: 0.9974 Acc: 0.7927\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.8252 Acc: 0.9223\n",
      "val Loss: 0.8648 Acc: 0.8953\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.6896 Acc: 0.9415\n",
      "val Loss: 0.7679 Acc: 0.9007\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.5904 Acc: 0.9546\n",
      "val Loss: 0.6917 Acc: 0.9028\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.5156 Acc: 0.9594\n",
      "val Loss: 0.6275 Acc: 0.9041\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.4533 Acc: 0.9619\n",
      "val Loss: 0.5726 Acc: 0.9048\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.3985 Acc: 0.9636\n",
      "val Loss: 0.5319 Acc: 0.9048\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.3537 Acc: 0.9638\n",
      "val Loss: 0.4924 Acc: 0.9055\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.3157 Acc: 0.9653\n",
      "val Loss: 0.4623 Acc: 0.9041\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2811 Acc: 0.9662\n",
      "val Loss: 0.4415 Acc: 0.9048\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.2518 Acc: 0.9657\n",
      "val Loss: 0.4205 Acc: 0.9109\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.2277 Acc: 0.9663\n",
      "val Loss: 0.4053 Acc: 0.9123\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.2063 Acc: 0.9689\n",
      "val Loss: 0.3944 Acc: 0.9055\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1851 Acc: 0.9694\n",
      "val Loss: 0.3769 Acc: 0.9055\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1673 Acc: 0.9711\n",
      "val Loss: 0.3709 Acc: 0.9150\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1527 Acc: 0.9728\n",
      "val Loss: 0.3486 Acc: 0.9164\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1367 Acc: 0.9755\n",
      "val Loss: 0.3437 Acc: 0.9062\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1245 Acc: 0.9745\n",
      "val Loss: 0.3472 Acc: 0.9150\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1119 Acc: 0.9755\n",
      "val Loss: 0.3311 Acc: 0.9171\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1052 Acc: 0.9760\n",
      "val Loss: 0.3166 Acc: 0.9130\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.0958 Acc: 0.9782\n",
      "val Loss: 0.3069 Acc: 0.9177\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.0925 Acc: 0.9770\n",
      "val Loss: 0.3151 Acc: 0.9177\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.0847 Acc: 0.9781\n",
      "val Loss: 0.3031 Acc: 0.9198\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.0868 Acc: 0.9793\n",
      "val Loss: 0.3029 Acc: 0.9211\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.0811 Acc: 0.9772\n",
      "val Loss: 0.3113 Acc: 0.9123\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.0707 Acc: 0.9811\n",
      "val Loss: 0.2875 Acc: 0.9252\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.0707 Acc: 0.9784\n",
      "val Loss: 0.3027 Acc: 0.9062\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.0613 Acc: 0.9842\n",
      "val Loss: 0.3015 Acc: 0.9157\n",
      "Training complete in 1m 33s\n",
      "Best val Acc: 0.932019\n",
      "[4 4 4 4 4]\n",
      "[[6.5858681e-03 3.0865753e-03 8.2912314e-04 9.1310067e-04 9.8856550e-01\n",
      "  1.9814664e-05]\n",
      " [1.5846780e-02 5.7159988e-03 1.8494719e-03 1.9806575e-03 9.7458148e-01\n",
      "  2.5617033e-05]\n",
      " [1.9886993e-02 7.2369594e-03 2.1636828e-03 2.8627983e-03 9.6782368e-01\n",
      "  2.5834570e-05]\n",
      " [1.8312940e-02 7.7453386e-03 1.7938456e-03 2.2900952e-03 9.6983778e-01\n",
      "  1.9999021e-05]\n",
      " [1.5127777e-02 6.5489658e-03 1.5352112e-03 1.6374437e-03 9.7513264e-01\n",
      "  1.7915218e-05]]\n",
      "                  0.0         1.0         2.0         3.0         4.0  \\\n",
      "precision    0.950397    0.971554    0.931264    0.875294    0.820000   \n",
      "recall       0.965726    0.942675    1.000000    0.757637    0.924812   \n",
      "f1-score     0.958000    0.956897    0.964409    0.812227    0.869258   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000   \n",
      "\n",
      "                  5.0  accuracy    macro avg  weighted avg  \n",
      "precision    1.000000  0.921955     0.924751      0.924038  \n",
      "recall       0.949721  0.921955     0.923429      0.921955  \n",
      "f1-score     0.974212  0.921955     0.922500      0.921384  \n",
      "support    537.000000  0.921955  2947.000000   2947.000000  \n"
     ]
    }
   ],
   "source": [
    "# Case 4. w/o data representation & LSTM_FCNs\n",
    "config = config4\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1a60a",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3085234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128)\n",
      "(7352,)\n",
      "(2947, 128)\n",
      "(2947,)\n"
     ]
    }
   ],
   "source": [
    "# Representation data\n",
    "data_dir = './data'\n",
    "\n",
    "train_x = pd.read_csv(os.path.join(data_dir, 'ts2vec_repr_train.csv'))\n",
    "train_y = pickle.load(open(os.path.join(data_dir, 'y_train.pkl'), 'rb'))\n",
    "\n",
    "test_x = pd.read_csv(os.path.join(data_dir, 'ts2vec_repr_test.csv'))\n",
    "test_y = pickle.load(open(os.path.join(data_dir, 'y_test.pkl'), 'rb'))\n",
    "\n",
    "train_data = {'x' : train_x, 'y' : train_y}\n",
    "test_data = {'x' : test_x, 'y' : test_y}\n",
    "\n",
    "print(train_x.shape)  #shape : (num_of_instance x representation_dims) = (7352, 9, 128)\n",
    "print(train_y.shape) #shape : (num_of_instance) = (7352, )\n",
    "print(test_x.shape)  #shape : (num_of_instance x representation_dims) = (2947, 9, 128)\n",
    "print(test_y.shape)  #shape : (num_of_instance) = (2947, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b370aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/150\n",
      "train Loss: 1.6923 Acc: 0.3856\n",
      "val Loss: 1.6072 Acc: 0.5350\n",
      "\n",
      "Epoch 6/150\n",
      "train Loss: 0.9423 Acc: 0.6948\n",
      "val Loss: 0.8945 Acc: 0.7410\n",
      "\n",
      "Epoch 11/150\n",
      "train Loss: 0.6747 Acc: 0.7614\n",
      "val Loss: 0.6682 Acc: 0.7791\n",
      "\n",
      "Epoch 16/150\n",
      "train Loss: 0.5527 Acc: 0.8062\n",
      "val Loss: 0.5651 Acc: 0.8178\n",
      "\n",
      "Epoch 21/150\n",
      "train Loss: 0.4724 Acc: 0.8357\n",
      "val Loss: 0.4980 Acc: 0.8321\n",
      "\n",
      "Epoch 26/150\n",
      "train Loss: 0.4103 Acc: 0.8563\n",
      "val Loss: 0.4440 Acc: 0.8484\n",
      "\n",
      "Epoch 31/150\n",
      "train Loss: 0.3651 Acc: 0.8786\n",
      "val Loss: 0.3966 Acc: 0.8790\n",
      "\n",
      "Epoch 36/150\n",
      "train Loss: 0.3195 Acc: 0.8941\n",
      "val Loss: 0.3584 Acc: 0.8960\n",
      "\n",
      "Epoch 41/150\n",
      "train Loss: 0.2863 Acc: 0.9044\n",
      "val Loss: 0.3313 Acc: 0.8939\n",
      "\n",
      "Epoch 46/150\n",
      "train Loss: 0.2542 Acc: 0.9182\n",
      "val Loss: 0.3054 Acc: 0.9041\n",
      "\n",
      "Epoch 51/150\n",
      "train Loss: 0.2301 Acc: 0.9281\n",
      "val Loss: 0.2858 Acc: 0.9123\n",
      "\n",
      "Epoch 56/150\n",
      "train Loss: 0.2122 Acc: 0.9320\n",
      "val Loss: 0.2721 Acc: 0.9164\n",
      "\n",
      "Epoch 61/150\n",
      "train Loss: 0.1963 Acc: 0.9398\n",
      "val Loss: 0.2596 Acc: 0.9184\n",
      "\n",
      "Epoch 66/150\n",
      "train Loss: 0.1876 Acc: 0.9384\n",
      "val Loss: 0.2486 Acc: 0.9225\n",
      "\n",
      "Epoch 71/150\n",
      "train Loss: 0.1703 Acc: 0.9464\n",
      "val Loss: 0.2429 Acc: 0.9218\n",
      "\n",
      "Epoch 76/150\n",
      "train Loss: 0.1627 Acc: 0.9478\n",
      "val Loss: 0.2337 Acc: 0.9239\n",
      "\n",
      "Epoch 81/150\n",
      "train Loss: 0.1557 Acc: 0.9478\n",
      "val Loss: 0.2272 Acc: 0.9259\n",
      "\n",
      "Epoch 86/150\n",
      "train Loss: 0.1484 Acc: 0.9500\n",
      "val Loss: 0.2224 Acc: 0.9320\n",
      "\n",
      "Epoch 91/150\n",
      "train Loss: 0.1426 Acc: 0.9498\n",
      "val Loss: 0.2209 Acc: 0.9266\n",
      "\n",
      "Epoch 96/150\n",
      "train Loss: 0.1376 Acc: 0.9522\n",
      "val Loss: 0.2160 Acc: 0.9327\n",
      "\n",
      "Epoch 101/150\n",
      "train Loss: 0.1312 Acc: 0.9565\n",
      "val Loss: 0.2100 Acc: 0.9347\n",
      "\n",
      "Epoch 106/150\n",
      "train Loss: 0.1305 Acc: 0.9543\n",
      "val Loss: 0.2079 Acc: 0.9347\n",
      "\n",
      "Epoch 111/150\n",
      "train Loss: 0.1281 Acc: 0.9519\n",
      "val Loss: 0.2054 Acc: 0.9354\n",
      "\n",
      "Epoch 116/150\n",
      "train Loss: 0.1251 Acc: 0.9539\n",
      "val Loss: 0.2061 Acc: 0.9361\n",
      "\n",
      "Epoch 121/150\n",
      "train Loss: 0.1196 Acc: 0.9558\n",
      "val Loss: 0.2033 Acc: 0.9375\n",
      "\n",
      "Epoch 126/150\n",
      "train Loss: 0.1166 Acc: 0.9549\n",
      "val Loss: 0.2014 Acc: 0.9354\n",
      "\n",
      "Epoch 131/150\n",
      "train Loss: 0.1142 Acc: 0.9565\n",
      "val Loss: 0.2035 Acc: 0.9361\n",
      "\n",
      "Epoch 136/150\n",
      "train Loss: 0.1124 Acc: 0.9580\n",
      "val Loss: 0.2005 Acc: 0.9375\n",
      "\n",
      "Epoch 141/150\n",
      "train Loss: 0.1097 Acc: 0.9594\n",
      "val Loss: 0.2008 Acc: 0.9375\n",
      "\n",
      "Epoch 146/150\n",
      "train Loss: 0.1108 Acc: 0.9561\n",
      "val Loss: 0.1993 Acc: 0.9375\n",
      "Training complete in 0m 25s\n",
      "Best val Acc: 0.938137\n",
      "[4 4 4 4 4]\n",
      "[[4.3652311e-05 3.2642618e-04 1.5995928e-06 6.6966298e-03 9.9292678e-01\n",
      "  4.8134893e-06]\n",
      " [4.7802228e-06 6.5756125e-05 3.8763639e-07 7.6732626e-03 9.9225473e-01\n",
      "  1.0959986e-06]\n",
      " [2.0228617e-06 4.7563150e-05 3.4184202e-07 9.7589809e-03 9.9019021e-01\n",
      "  9.4529292e-07]\n",
      " [2.6051623e-06 5.3089814e-05 3.5020051e-07 8.0245109e-03 9.9191850e-01\n",
      "  1.0092582e-06]\n",
      " [2.4374933e-06 5.9906775e-05 3.8326880e-07 7.8893155e-03 9.9204683e-01\n",
      "  1.0995636e-06]]\n",
      "                  0.0         1.0         2.0         3.0         4.0    5.0  \\\n",
      "precision    0.952965    0.960465    0.868922    0.828125    0.794737    1.0   \n",
      "recall       0.939516    0.876858    0.978571    0.755601    0.851504    1.0   \n",
      "f1-score     0.946193    0.916759    0.920493    0.790202    0.822142    1.0   \n",
      "support    496.000000  471.000000  420.000000  491.000000  532.000000  537.0   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision  0.899559     0.900869      0.901393  \n",
      "recall     0.899559     0.900342      0.899559  \n",
      "f1-score   0.899559     0.899298      0.899247  \n",
      "support    0.899559  2947.000000   2947.000000  \n"
     ]
    }
   ],
   "source": [
    "# Case 5. w/ data representation & fully-connected layers\n",
    "config = config5\n",
    "data_classification = mc.Classification(config, train_data, test_data)\n",
    "pred, prob = data_classification.getResult()\n",
    "\n",
    "# test_loader : shuffle = False \n",
    "print(pred[:5]) # shape : (2947, )\n",
    "print(prob[:5]) # shape : (2947, 6)\n",
    "\n",
    "print(pd.DataFrame(classification_report(test_data['y'], pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43781a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8c93687a9f3cac7ea1a38989caebc63561608f7a862e4f9a11f0ba4f68d9d9a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
