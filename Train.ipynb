{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import config\n",
    "import utils\n",
    "import main_regression as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 42\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "877996be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def Saver(model_name):\n",
    "\n",
    "    os.makedirs('./ckpt', exist_ok=True)\n",
    "    os.makedirs('./ckpt/' + model_name, exist_ok=True)\n",
    "    \n",
    "    model_dir_path = './ckpt/' + model_name\n",
    "    runs = sorted(glob.glob(os.path.join('./', model_name, '/experiment_*')))\n",
    "    indices = []\n",
    "    for tmp in runs:\n",
    "        tmp_num = tmp.split(\"\\\\\")[-1]\n",
    "        tmp_num = int(tmp_num.split(\"_\")[-1])\n",
    "        indices.append(tmp_num)\n",
    "        \n",
    "    if len(indices) == 0:\n",
    "        run_id = str(0)\n",
    "    else:\n",
    "        run_id = np.max(indices) + 1\n",
    "\n",
    "    experiment_dir = os.path.join(model_dir_path, '/', f'experiment_{str(run_id)}')\n",
    "\n",
    "    os.makedirs(experiment_dir, exist_ok = True)\n",
    "    \n",
    "\n",
    "    return experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 24, 144)\n",
      "(95,)\n",
      "(42, 24, 144)\n",
      "(42,)\n",
      "inputSize(train_x.shape[1]): 24\n",
      "sequenceLenth (train_x.shape[2]): 144\n",
      "Save MinMaxScaler in path: ./scaler/minmax_scaler_x.pkl\n",
      "Save MinMaxScaler in path: ./scaler/minmax_scaler_y.pkl\n"
     ]
    }
   ],
   "source": [
    "# load raw data\n",
    "# [\"LSTM_rg\", \"GRU_rg\", \"CNN_1D_rg\", \"LSTM_FCNs_rg\"]는 사용 데이터가 동일하기 때문에 편의상 utils.load_data에서 model_name을 'LSTM_rg'로 설정하여 불러온 데이터를 함께 사용함\n",
    "data_root_dir = './data/'\n",
    "train_x, train_y, test_x, test_y = utils.load_data(data_root_dir, model_name='LSTM_rg')  # shape=(num_of_instance, input_dims, time_steps)\n",
    "\n",
    "# split train data into train/valiation data\n",
    "# train data를 랜덤으로 test_size=split_ratio에 대하여 train/validation set으로 분할 (관측치 단위 데이터)\n",
    "split_ratio = 0.2\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split_ratio, shuffle=True)\n",
    "\n",
    "# normalization\n",
    "scaler_x_path = './scaler/minmax_scaler_x.pkl'\n",
    "scaler_y_path = './scaler/minmax_scaler_y.pkl'\n",
    "train_x, valid_x = utils.get_train_val_data(train_x, valid_x, scaler_x_path)\n",
    "train_y, valid_y = utils.get_train_val_data(train_y, valid_y, scaler_y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: LSTM_rg\n",
      "\n",
      "Epoch 1/100\n",
      "train Loss: 0.0566\n",
      "val Loss: 0.0569\n",
      "\n",
      "Epoch 50/100\n",
      "train Loss: 0.0434\n",
      "val Loss: 0.0434\n",
      "\n",
      "Epoch 100/100\n",
      "train Loss: 0.0326\n",
      "val Loss: 0.0346\n",
      "\n",
      "Training complete in 0m 5s\n",
      "Best val MSE: 0.034624\n"
     ]
    }
   ],
   "source": [
    "# Case 1. LSTM model (w/o data representation)\n",
    "model_name = 'LSTM_rg'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "exp_path = Saver(model_name)\n",
    "data_reg = mr.Regression(model_params)\n",
    "best_model = data_reg.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "data_reg.save_model(best_model, best_model_path=os.path.join(exp_path, model_params[\"best_model\"]))  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: GRU_rg\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.0489\n",
      "val Loss: 0.0434\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0342\n",
      "val Loss: 0.0434\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0218\n",
      "val Loss: 0.0316\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0187\n",
      "val Loss: 0.0232\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0160\n",
      "val Loss: 0.0187\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0149\n",
      "val Loss: 0.0210\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0141\n",
      "val Loss: 0.0207\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0120\n",
      "val Loss: 0.0214\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0104\n",
      "val Loss: 0.0217\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0092\n",
      "val Loss: 0.0194\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0081\n",
      "val Loss: 0.0173\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0074\n",
      "val Loss: 0.0167\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0066\n",
      "val Loss: 0.0169\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0058\n",
      "val Loss: 0.0166\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0074\n",
      "val Loss: 0.0194\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0053\n",
      "val Loss: 0.0207\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0043\n",
      "val Loss: 0.0209\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0041\n",
      "val Loss: 0.0283\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0195\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0052\n",
      "val Loss: 0.0222\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0215\n",
      "\n",
      "Training complete in 0m 50s\n",
      "Best val MSE: 0.013994\n"
     ]
    }
   ],
   "source": [
    "# Case 2. GRU (w/o data representation)\n",
    "model_name = 'GRU_rg'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "exp_path = Saver(model_name)\n",
    "data_reg = mr.Regression(model_params)\n",
    "best_model = data_reg.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "data_reg.save_model(best_model, best_model_path=os.path.join(exp_path, model_params[\"best_model\"]))  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: CNN_1D_rg\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.0499\n",
      "val Loss: 0.0436\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0363\n",
      "val Loss: 0.0441\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0315\n",
      "val Loss: 0.0448\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0270\n",
      "val Loss: 0.0450\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0238\n",
      "val Loss: 0.0458\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0187\n",
      "val Loss: 0.0479\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0160\n",
      "val Loss: 0.0483\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0132\n",
      "val Loss: 0.0493\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0107\n",
      "val Loss: 0.0495\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0083\n",
      "val Loss: 0.0484\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0071\n",
      "val Loss: 0.0490\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0061\n",
      "val Loss: 0.0485\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0049\n",
      "val Loss: 0.0483\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0038\n",
      "val Loss: 0.0495\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0503\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0501\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0518\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0517\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0506\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0016\n",
      "val Loss: 0.0515\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0512\n",
      "\n",
      "Training complete in 0m 10s\n",
      "Best val MSE: 0.042776\n"
     ]
    }
   ],
   "source": [
    "# Case 3. CNN_1D (w/o data representation)\n",
    "model_name = 'CNN_1D_rg'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "exp_path = Saver(model_name)\n",
    "data_reg = mr.Regression(model_params)\n",
    "best_model = data_reg.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "data_reg.save_model(best_model, best_model_path=os.path.join(exp_path, model_params[\"best_model\"]))  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: LSTM_FCNs_rg\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.0531\n",
      "val Loss: 0.0456\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0156\n",
      "val Loss: 0.0420\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0070\n",
      "val Loss: 0.0409\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0034\n",
      "val Loss: 0.0337\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0036\n",
      "val Loss: 0.0366\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0030\n",
      "val Loss: 0.0375\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0046\n",
      "val Loss: 0.0367\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0025\n",
      "val Loss: 0.0396\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0018\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0023\n",
      "val Loss: 0.0320\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0029\n",
      "val Loss: 0.0358\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0368\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0013\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0340\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0021\n",
      "val Loss: 0.0347\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0028\n",
      "val Loss: 0.0356\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0009\n",
      "val Loss: 0.0295\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0010\n",
      "val Loss: 0.0311\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0006\n",
      "val Loss: 0.0310\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0008\n",
      "val Loss: 0.0324\n",
      "\n",
      "Training complete in 0m 46s\n",
      "Best val MSE: 0.026001\n"
     ]
    }
   ],
   "source": [
    "# Case 4. LSTM_FCNs (w/o data representation)\n",
    "model_name = 'LSTM_FCNs_rg'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "exp_path = Saver(model_name)\n",
    "data_reg = mr.Regression(model_params)\n",
    "best_model = data_reg.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "data_reg.save_model(best_model, best_model_path=os.path.join(exp_path, model_params[\"best_model\"]))  # 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save MinMaxScaler in path: ./scaler/minmax_scaler_x_repr.pkl\n",
      "Save MinMaxScaler in path: ./scaler/minmax_scaler_y_repr.pkl\n"
     ]
    }
   ],
   "source": [
    "# load representation data\n",
    "data_root_dir = './data/'\n",
    "train_x, train_y, test_x, test_y = utils.load_data(data_root_dir, model_name='FC_rg')  # shape=(num_of_instance, embedding_dim)\n",
    "\n",
    "# split train data into train/valiation data\n",
    "# train data를 랜덤으로 test_size=split_ratio에 대하여 train/validation set으로 분할\n",
    "split_ratio = 0.2\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=split_ratio, shuffle=True)\n",
    "\n",
    "# normalization\n",
    "scaler_x_path = './scaler/minmax_scaler_x_repr.pkl'\n",
    "scaler_y_path = './scaler/minmax_scaler_y_repr.pkl'\n",
    "train_x, valid_x = utils.get_train_val_data(train_x, valid_x, scaler_x_path)\n",
    "train_y, valid_y = utils.get_train_val_data(train_y, valid_y, scaler_y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: FC_rg\n",
      "\n",
      "Epoch 1/1000\n",
      "train Loss: 0.0522\n",
      "val Loss: 0.0415\n",
      "\n",
      "Epoch 50/1000\n",
      "train Loss: 0.0433\n",
      "val Loss: 0.0345\n",
      "\n",
      "Epoch 100/1000\n",
      "train Loss: 0.0416\n",
      "val Loss: 0.0340\n",
      "\n",
      "Epoch 150/1000\n",
      "train Loss: 0.0416\n",
      "val Loss: 0.0335\n",
      "\n",
      "Epoch 200/1000\n",
      "train Loss: 0.0392\n",
      "val Loss: 0.0332\n",
      "\n",
      "Epoch 250/1000\n",
      "train Loss: 0.0382\n",
      "val Loss: 0.0329\n",
      "\n",
      "Epoch 300/1000\n",
      "train Loss: 0.0375\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 350/1000\n",
      "train Loss: 0.0368\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 400/1000\n",
      "train Loss: 0.0361\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 450/1000\n",
      "train Loss: 0.0347\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 500/1000\n",
      "train Loss: 0.0344\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 550/1000\n",
      "train Loss: 0.0332\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 600/1000\n",
      "train Loss: 0.0327\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 650/1000\n",
      "train Loss: 0.0309\n",
      "val Loss: 0.0323\n",
      "\n",
      "Epoch 700/1000\n",
      "train Loss: 0.0285\n",
      "val Loss: 0.0324\n",
      "\n",
      "Epoch 750/1000\n",
      "train Loss: 0.0298\n",
      "val Loss: 0.0325\n",
      "\n",
      "Epoch 800/1000\n",
      "train Loss: 0.0284\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 850/1000\n",
      "train Loss: 0.0279\n",
      "val Loss: 0.0327\n",
      "\n",
      "Epoch 900/1000\n",
      "train Loss: 0.0287\n",
      "val Loss: 0.0328\n",
      "\n",
      "Epoch 950/1000\n",
      "train Loss: 0.0297\n",
      "val Loss: 0.0330\n",
      "\n",
      "Epoch 1000/1000\n",
      "train Loss: 0.0247\n",
      "val Loss: 0.0331\n",
      "\n",
      "Training complete in 0m 6s\n",
      "Best val MSE: 0.032240\n"
     ]
    }
   ],
   "source": [
    "# Case 5. fully-connected layers (w/ data representation)\n",
    "model_name = 'FC_rg'\n",
    "model_params = config.model_config[model_name]\n",
    "\n",
    "exp_path = Saver(model_name)\n",
    "data_reg = mr.Regression(model_params)\n",
    "best_model = data_reg.train_model(train_x, train_y, valid_x, valid_y)  # 모델 학습\n",
    "data_reg.save_model(best_model, best_model_path=os.path.join(exp_path, model_params[\"best_model\"]))  # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('hwang')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4f311b633f277f5e4d199db5715cd5ecdec0742926e2e6ae6b04aa7fd42957fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
